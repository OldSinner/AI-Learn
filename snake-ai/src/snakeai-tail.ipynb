{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf3b597",
   "metadata": {},
   "source": [
    "# 1. Przygotowanie środowiska programistycznego\n",
    "Zaimportowanie niezbędnych bibliotek i narzędzi do pracy z danymi oraz modelami uczenia maszynowego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab29931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.32.62, Python 3.14.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import sys\n",
    "import random\n",
    "from collections import defaultdict,deque\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from dataclasses import dataclass\n",
    "import enum\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "SCREEN_WIDTH = 640\n",
    "SCREEN_HEIGHT = 640\n",
    "FPS = 10\n",
    "SNAKE = (0, 255, 0)\n",
    "EMPTY = (0, 0, 0)\n",
    "FOOD = (255, 0, 0)\n",
    "CELL_GRID = (20, 20)\n",
    "CELL_SIZE = (SCREEN_WIDTH / CELL_GRID[0], SCREEN_HEIGHT / CELL_GRID[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e5739",
   "metadata": {},
   "source": [
    "# 2. Metody i typy pomocniczne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262110b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    LEFT = 1\n",
    "    RIGHT = 2\n",
    "    STRAIGHT = 3\n",
    "def tuple_to_action(t) -> Action:\n",
    "    return list(Action)[t]\n",
    "def save_agent(agent, filename=\"q_table.pkl\"):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(dict(agent.Q_Table), f)\n",
    "def load_agent(agent, filename=\"q_table.pkl\"):\n",
    "    import pickle\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        agent.Q_Table = defaultdict(lambda: np.zeros(3), data)\n",
    "@dataclass\n",
    "class Vector:\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Vector):\n",
    "            return self.x == other.x and self.y == other.y\n",
    "        return False\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Vector):\n",
    "            return Vector(self.x + other.x, self.y + other.y)\n",
    "        return NotImplemented\n",
    "    \n",
    "    \n",
    "    \n",
    "def live_plot(episode_rewards, episode_points=None):\n",
    "    clear_output(wait=True)  # czyści poprzedni wykres\n",
    "    episodes = np.arange(1, len(episode_rewards) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    # nagrody\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episodes, episode_rewards, label=\"Total reward\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Reward per Episode\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # punkty\n",
    "    if episode_points is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(episodes, episode_points, label=\"Points\", color=\"orange\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Points\")\n",
    "        plt.title(\"Points per Episode\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66adbb",
   "metadata": {},
   "source": [
    "# 3. Logika gry Snake z AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "        pygame.display.set_caption(\"Snake AI\")\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.running = True\n",
    "        self.food = Vector(0, 0)\n",
    "        self.direction = Vector(1, 0)\n",
    "        self.snake : deque[Vector] = deque()\n",
    "        self.snake.appendleft(Vector(CELL_GRID[0] // 2, CELL_GRID[1] // 2))\n",
    "        self.rand_food()\n",
    "        self.points = 0\n",
    "\n",
    "\n",
    "    def handle_keydown(self, key):\n",
    "        if key == pygame.K_q:\n",
    "            self.running = False\n",
    "        \n",
    "    def handle_action(self, action: Action):\n",
    "        dx, dy = self.direction.x, self.direction.y\n",
    "        if action == Action.LEFT:\n",
    "            self.direction = Vector(-dy, dx)\n",
    "        elif action == Action.RIGHT:\n",
    "            self.direction = Vector(dy, -dx)\n",
    "        elif action == Action.STRAIGHT:\n",
    "            pass\n",
    "        \n",
    "    def handle_events(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                self.running = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                self.handle_keydown(event.key)\n",
    "\n",
    "    def rand_food(self):\n",
    "        while True:\n",
    "            x = random.randrange(CELL_GRID[0])\n",
    "            y = random.randrange(CELL_GRID[1])\n",
    "            self.food = Vector(x, y)\n",
    "            if not self.snake == self.food:\n",
    "                break\n",
    "\n",
    "    def get_distance(self) -> int:\n",
    "        return abs(self.snake[0].x - self.food.x) + abs(self.snake[0].y - self.food.y)\n",
    "\n",
    "\n",
    "    def step(self, action : Action) -> tuple[tuple, float, bool]:\n",
    "        old_distance = self.get_distance()\n",
    "        self.handle_events()\n",
    "        self.handle_action(action)\n",
    "        new_head = self.snake[0] + self.direction \n",
    "        self.snake.appendleft(new_head)\n",
    "        done = False\n",
    "        reward = -0.05  # Reduced penalty for each step\n",
    "        new_distance = self.get_distance()\n",
    "\n",
    "        if new_distance < old_distance:\n",
    "            reward += 0.5  # Better reward for moving closer\n",
    "        elif new_distance > old_distance:\n",
    "            reward -= 0.25  # Penalty for moving away\n",
    "            \n",
    "        if len(self.snake) > 1:\n",
    "            for snakepart in list(self.snake)[1:]:\n",
    "                if self.snake[0] == snakepart:\n",
    "                    reward = -10\n",
    "                    print(\"Debil sie zjadł\")\n",
    "                    done = True\n",
    "                    return (tuple(self.get_state()), reward, done)\n",
    "                    \n",
    "            \n",
    "        if self.snake[0] == self.food:\n",
    "            self.rand_food()\n",
    "            self.points += 1\n",
    "            reward = 10  # Large reward for eating food\n",
    "        else:\n",
    "            self.snake.pop()\n",
    "        \n",
    "            \n",
    "        if (\n",
    "            self.snake[0].x > CELL_GRID[0]\n",
    "            or self.snake[0].x < 0\n",
    "            or self.snake[0].y > CELL_GRID[1]\n",
    "            or self.snake[0].y < 0\n",
    "        ):\n",
    "            reward = -10\n",
    "            done = True\n",
    "        self.draw()\n",
    "        self.clock.tick(FPS)\n",
    "        return (tuple(self.get_state()), reward, done)\n",
    "\n",
    "    def step_with_keyboard(self) -> tuple[tuple, float, bool]:\n",
    "        action = Action.STRAIGHT \n",
    "        \n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                self.running = False\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_q:\n",
    "                    self.running = False\n",
    "                elif event.key in (pygame.K_LEFT, pygame.K_a):\n",
    "                    action = Action.LEFT\n",
    "                elif event.key in (pygame.K_RIGHT, pygame.K_d):\n",
    "                    action = Action.RIGHT\n",
    "                elif event.key in (pygame.K_UP, pygame.K_DOWN, pygame.K_w, pygame.K_s):\n",
    "                    action = Action.STRAIGHT\n",
    "        \n",
    "        return self.step(action)\n",
    "\n",
    "    def get_state(self) -> tuple:\n",
    "        food_front = False\n",
    "        food_left = False\n",
    "        food_right = False\n",
    "\n",
    "        if self.direction == Vector(1, 0):  # Moving RIGHT\n",
    "            food_front = self.snake[0].x < self.food.x\n",
    "            food_left = self.snake[0].y > self.food.y\n",
    "            food_right = self.snake[0].y < self.food.y\n",
    "        elif self.direction == Vector(-1, 0):  # Moving LEFT\n",
    "            food_front = self.snake[0].x > self.food.x\n",
    "            food_left = self.snake[0].y < self.food.y\n",
    "            food_right = self.snake[0].y > self.food.y\n",
    "        elif self.direction == Vector(0, 1):  # Moving DOWN\n",
    "            food_front = self.snake[0].y < self.food.y\n",
    "            food_left = self.snake[0].x < self.food.x\n",
    "            food_right = self.snake[0].x > self.food.x\n",
    "        elif self.direction == Vector(0, -1):  # Moving UP\n",
    "            food_front = self.snake[0].y > self.food.y\n",
    "            food_left = self.snake[0].x > self.food.x\n",
    "            food_right = self.snake[0].x < self.food.x\n",
    "\n",
    "        # Add distance information for better learning\n",
    "        distance = self.get_distance()\n",
    "        distance_level = min(distance // 5, 3)  # 0-3 levels\n",
    "        \n",
    "        return (food_front, food_left, food_right, distance_level)\n",
    "\n",
    "    def reset(self):\n",
    "        self.rand_food()\n",
    "        self.snake = deque()\n",
    "        self.snake.append(Vector(CELL_GRID[0] // 2, CELL_GRID[1] // 2))\n",
    "        self.points = 0\n",
    "\n",
    "    def draw(self):\n",
    "        self.screen.fill(EMPTY)\n",
    "        # Draw snake\n",
    "        for cell in self.snake:\n",
    "            snake_rect = pygame.Rect(\n",
    "            cell.x * CELL_SIZE[0],\n",
    "            cell.y * CELL_SIZE[1],\n",
    "            CELL_SIZE[0],\n",
    "            CELL_SIZE[1],\n",
    "            )\n",
    "            pygame.draw.rect(self.screen, SNAKE, snake_rect)\n",
    "\n",
    "            \n",
    "        # Draw food\n",
    "        food_rect = pygame.Rect(\n",
    "            self.food.x * CELL_SIZE[0],\n",
    "            self.food.y * CELL_SIZE[1],\n",
    "            CELL_SIZE[0],\n",
    "            CELL_SIZE[1],\n",
    "        )\n",
    "        pygame.draw.rect(self.screen, FOOD, food_rect)\n",
    "\n",
    "        pygame.display.flip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef19a1",
   "metadata": {},
   "source": [
    "# 4. Tworzenia agenta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444f6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomAction() -> tuple[int, int, int]:\n",
    "    index = random.randint(0, 2)\n",
    "    return (1 if index == 0 else 0, 1 if index == 1 else 0, 1 if index == 2 else 0)\n",
    "\n",
    "\n",
    "n_actions = 3\n",
    "class AgentQ:\n",
    "    def __init__(self, game: Game) -> None:\n",
    "        self.Q_Table = defaultdict(lambda: np.zeros(n_actions))\n",
    "        self.alpha = 0.1  # Lower learning rate for stability\n",
    "        self.gamma = 0.95  # Higher discount factor\n",
    "        self.epsilon :float = 1 \n",
    "        self.game = game\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, n_actions - 1)\n",
    "        else:\n",
    "            return argmax(self.Q_Table[state])\n",
    "\n",
    "    def make_step(self):\n",
    "        old_state = tuple(self.game.get_state())\n",
    "        action = self.get_action(old_state)\n",
    "        new_state, reward, done = self.game.step(tuple_to_action(action))\n",
    "        current_q = self.Q_Table[old_state][action]\n",
    "        max_future_q = 0 if done else np.max(self.Q_Table[new_state])\n",
    "        self.Q_Table[old_state][action] = self.calculate_q(current_q, max_future_q, reward)\n",
    "        return new_state, reward, done\n",
    "\n",
    "    def calculate_q(self, current_q, max_future_q, reward):\n",
    "        return current_q + self.alpha * (reward + self.gamma * max_future_q - current_q)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd3a23",
   "metadata": {},
   "source": [
    "# 5. Pętla szkoląca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8063c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debil sie zjadł\n",
      "Debil sie zjadł\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# agent = AgentQ(game)\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[43mgame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep_with_keyboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# train_agent(agent)\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     42\u001b[39m     pygame.quit()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 105\u001b[39m, in \u001b[36mGame.step_with_keyboard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    102\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m event.key \u001b[38;5;129;01min\u001b[39;00m (pygame.K_UP, pygame.K_DOWN, pygame.K_w, pygame.K_s):\n\u001b[32m    103\u001b[39m             action = Action.STRAIGHT\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mGame.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     84\u001b[39m     done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.draw()\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFPS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_state()), reward, done)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train_agent(agent : AgentQ, num_episodes=10000, epsilon_decay=0.9995, min_epsilon=0.01):\n",
    "    episode_rewards = []\n",
    "    episode_points = []\n",
    "    avg_rewards = []\n",
    "    avg_points = []\n",
    "    for episode in range(num_episodes):\n",
    "        agent.game.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        if not agent.game.running:\n",
    "            break\n",
    "        while not done and steps < 500:  # Limit steps to prevent infinite episodes\n",
    "            _, reward, done = agent.make_step()\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "        episode_rewards.append(total_reward)\n",
    "        episode_points.append(agent.game.points)\n",
    "        agent.epsilon = max(min_epsilon, agent.epsilon * epsilon_decay)\n",
    "        if episode % 50 == 0:\n",
    "            avg_reward = statistics.mean(episode_rewards)\n",
    "            avg_point = statistics.mean(episode_points)\n",
    "            avg_rewards.append(avg_reward)\n",
    "            avg_points.append(avg_point)\n",
    "            episode_rewards = []\n",
    "            episode_points = []\n",
    "            live_plot(avg_rewards, avg_points)\n",
    "            print(f\"Episode {episode}/{num_episodes}, Epsilon: {agent.epsilon:.4f}, Avg Reward: {np.mean(episode_rewards[-100:]):.3f}\")\n",
    "        if episode % 100 == 0:\n",
    "            save_agent(agent, f\"q_table_{episode}.pkl\")\n",
    "    plt.ioff() \n",
    "    plt.show()\n",
    "try:\n",
    "    game = Game()\n",
    "    # agent = AgentQ(game)\n",
    "    \n",
    "    while True:\n",
    "        game.step_with_keyboard()\n",
    "\n",
    "    # train_agent(agent)\n",
    "finally:\n",
    "    pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
